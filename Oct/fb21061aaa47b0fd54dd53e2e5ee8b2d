Another diet study, another controversy and the public is left wondering what to make of it. This time it’s a series of studies in the Annals of Internal Medicine  by an international group of researchers concluding people need not reduce their consumption of red and processed meat. Over the past few years, study after study has indicated eating red and processed meat is bad for your health to the point where the World Health Organization lists red meat as a probable carcinogen and processed meat as a carcinogen. This new study doesn’t dispute the finding of a possible increased risk for heart disease, cancer and early death from eating meat. However, the panel of international nutritional scientists concluded the risk was so small and the studies of too poor quality to justify any recommendation. The authors conducted a study of studies. This is done when findings of one or two pieces of research may not be definitive. Or the effect of something is so small you need to pool smaller studies into a larger one. From this, the authors found reducing unprocessed red meat consumption by three servings in a week was associated with an approximately eight per cent lower lifetime risk of heart disease, cancer and early death. These findings are similar to many studies before it and aren’t surprising. However, this is a much smaller change in improved health than would be achieved by stopping smoking, eliminating hypertension or starting physical activity. Read more:
      Yes, we still need to cut down on red and processed meat Where the authors differed from previous studies was in how they assessed both the research and the benefit of reducing meat consumption to make their recommendations. They used a standard practice in medicine to grade the quality of the studies and found them to be poor. In addition, they interpreted the benefit of unprocessed red meat reduction (approximately eight per cent lower lifetime risk) to be small. They collectively recommended against the need for people to reduce meat consumption. This sent nutrition and public health scientists into an uproar, calling the study highly irresponsible to public health and citing grave concerns. Nutritional science is messy. Most of our guidelines are based on observational studies in which scientists ask people what, and how much, they have eaten in a given time period (usually the previous year), and then follow them for years to see how many people get a disease or die. A lot of times, diet is assessed only once, but we know people’s diets change over time. More robust studies ask people to report their diet multiple times. This can take into account changes. However, self-reported dietary data is known to be poor. People may know what they ate, but have trouble knowing how much and even how it was prepared. All of which can affect the nutritional value of a food. These studies also only identify associations, and not causation. This doesn’t mean causation isn’t possible, just the design of the study cannot show it. Usually, if a number of observational studies show similar results, our confidence of a causal effect increases. But in the end, this is still weak evidence. The gold standard in medical science is the randomized controlled trial in which people are assigned by chance to various different groups, the most familiar being a new drug compared to placebo. Some say we shouldn’t use the same standard in nutrition because it’s hard to do. Sticking to diets is extremely challenging, which makes it hard to conduct a study long enough to see an effect on disease, not to mention the costs involved in doing so. In addition, nutrition is complex. It’s not like smoking, where the goal is to not smoke at all. We need to eat to live. Therefore when we stop eating one thing, we likely replace it with another. What food we choose as the replacement can be just as important to our overall health as what food was stopped. There are numerous instances when observational studies have shown a protective effect of a nutrient only to be disproven in randomized trials. Vitamins C, D and E, folic acid and beta carotene supplements were all believed to prevent disease in observational studies. These claims went unproven in randomized studies. In the case of beta carotene supplementation, for example, an increased risk for lung cancer was found. By not holding nutrition sciences to the same bar as other medical sciences, we may be doing the public more harm than good. From a public health perspective, a small individual change replicated throughout the population can lead to large changes at the societal level. This could result in changes in the average age of disease onset or death rates, which in turn could result in lower health-care costs. And for this reason, guidelines are needed, but if all we have is bad evidence, then we come up with bad guidelines. Throughout the world, life expectancy has increased remarkably in recent centuries. While there are many reasons for this, advances in nutritional sciences are a key one. This knowledge has led to the elimination of nutritional deficiencies. Most people don’t worry too much about rickets, goiters or scurvy in North America these days. In the future, however, additional research in nutrition is going to lead to less remarkable gains in quality and length of life, measured in days, not years. While the war of words among scientists and public health officials continue, the real disservice is to the general public who look to us for leadership. Over time this ongoing inflamed rhetoric begins to turn into white noise, which gets ignored at best, and can diminish the trust in nutrition science. One may wonder if we should stop nutritional research altogether until we can get it right. Scott Lear writes the weekly blog Feel Healthy with Dr. Scott Lear. [ Expertise in your inbox. Sign up for The Conversation’s newsletter and get a digest of academic takes on today’s news, every day. ]