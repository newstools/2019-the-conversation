Not content with monitoring almost everything you do online, Facebook now wants to read your mind as well. The social media giant recently announced a breakthrough in its plan to create a device that reads people’s brainwaves to allow them to type just by thinking. And Elon Musk wants to go even further. One of the Tesla boss’s other companies, Neuralink, is developing a brain implant to connect people’s minds directly to a computer. Musk admits that he takes inspiration from science fiction, and that he wants to make sure humans can “keep up” with artificial intelligence. He seems to have missed the part of sci-fi that acts as a warning for the implications of technology. These mind-reading systems could affect our privacy, security, identity, equality and personal safety. Do we really want all that left to companies with philosophies such as that of Facebook’s former mantra, “move fast and break things”? Though they sound futuristic, the technologies needed to make brainwave-reading devices are not that dissimilar to the standard MRI (magnetic resonance imaging) and EEG (electroencephalography) neuroscience tools used in hospitals all over the world. You can already buy a kit to control a drone with your mind, so using one to type out words is, in some ways, not that much of a leap. The advance will likely be due to the use of machine learning to sift through huge quantities of data collected from our brains and find the patterns in neuron activity that link thoughts to specific words. A brain implant is likely to take a lot longer to develop, and it’s important to separate out the actual achievements of Neuralink from media hype and promotion. But Neuralink has made simultaneous improvements in materials for electrodes and robot-assisted surgery to implant them, packaging the technology neatly so it can be read via USB. Facebook and Neuralink’s plans may build on established medical practice. But when companies are collecting thoughts directly from our brains, the ethical issues are very different. Any system that could collect data directly from our brains has clear privacy risks. Privacy is about consent. But it is very difficult to give proper consent if someone is tapping directly into our thoughts. Silicon Valley companies (and governments) already surreptitiously gather as much data on us as they can and use it in ways we’d rather they didn’t. How sure can we be that our random and personal thoughts won’t be captured and studied alongside the instructions we want to give the technology? One of the existing ethical issues with data gathering is discrimination based on attributes such as gender or race that can be discerned from the data. Providing a window into people’s minds could make it easier to determine other things that might form the basis of prejudice, such as sexuality or political ideology, or even different ways of thinking that might include things like autism. With a system that taps directly into your brain, not only could your thoughts be stolen, but it’s also possible they could be manipulated as well. Brain stimulation is already being developed to help treat PTSD and reduce violence. There are even sensational claims that it can be used to upload knowledge directly just like in the film The Matrix. A predictable step would be to combine the “in” and “out” technologies for a two-way brain-computer interface. The potential for governments to make us more compliant, for employers to force us to work harder, or for companies to make us want more of their products underlines just how seriously we should take this technology. If mind-reading devices become the normal way to interact with computers, we may end up with little choice but to use them in order to keep up with more productive colleagues. (Imagine someone today applying for an office job but refusing to use email.) And if Neuralink-style implants become the norm, this could also lead to greater inequality determined by what level of kit you could afford to have installed. Elon Musk has stated that the enormous loan required to afford Neuralink surgery would be offset by potential earnings for the “enhanced”. The idea of people feeling pressured to take on huge debts to have surgery just to keep their job comes straight from a sci-fi dystopia. On top of all this is the more direct physical threat of having systems physically intruding on our brains. While some people may want to modify their brain with a computer interface (there are already plenty of experimental biohackers), to roll this out on a large scale would require massive and thorough testing. Given Silicon Valley’s reputation (and penchant) for breaking things rather than stopping to think them through, these systems will need close regulation and ethical review even before testing begins. Otherwise it risks creating mutilated human guinea pigs. For all this, there could be huge advantages to continuing research in this area, particularly for those suffering from paralysis or sensory impairment. But Silicon Valley should not be able to dictate the way these technologies are developed and deployed. If they do, it may radically reshape the way we identify as human.